# -*- coding: utf-8 -*-
"""tflite_sinmewave_trainingipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XAW2UtdKku0lu3AqHIiUN7r9G1WEExG-

# Grundlegende Einstellungen
Basierend auf einer [Anleitung](https://gist.github.com/ShawnHymel/79237fe6aee5a3653c497d879f746c0c) von [Shawn Hymel](https://gist.github.com/ShawnHymel)

Erweitert von [Niklas Weber](https://github.com/nikipediaweber)

Tensorflow Version 2.1 verwenden:
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.1

"""Benötigte libraries importieren:"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import math
from tensorflow.keras import layers

"""Verwendete Versionen ausgeben:"""

!python --versions
print('Numpy' + np.__version__)
print('Tensorflow' + tf.__version__)
#print('Keras' + tf.keras.__version__)

"""Einstellungen für Datensatzerzeugung:

"""

nsamples = 1000     #Anzahl der Daten im Datensatz
val_ratio = 0.2     #Prozentsatz der Daten, die für validation beiseitegelegt werden
test_ratio = 0.2    #Prozentsatz der Daten, die für das Testen beiseitegelegt werden

"""Einstellungen für das Modell"""

#Name des Modells festlegen
tflite_model_name = 'sine_model' #wird mit .tflite am Ende abgespeichert
c_model_name = 'sine_model'      #wird mit .h am Ende abgespeichert

"""# Erzeugen der Trainings-, Validierungs- und Testdaten

Zufälllige Werte zwischen 0 und 2pi generieren. Diese werden als x-Werte der Sinusfunktion verwendet.
"""

np.random.seed(42)
x_values = np.random.uniform(low=0, high=(2*math.pi), size = nsamples)
plt.plot(x_values)

"""Berechnen der den x Werten zugehörigen y Werte:

"""

y_values_clean = np.sin(x_values)
plt.plot(x_values,y_values_clean,'.')

"""Nun noch mit Gaußschem Rauschen um die ungenauigkeit der Testdaten zu simulieren:"""

y_values = np.sin(x_values)+(0.1*np.random.randn(x_values.shape[0]))
plt.plot(x_values,y_values,'.')

"""Aufteilen in Trainings-, Validierungs- und Testdaten"""

val_split = int(val_ratio * nsamples) #bestimmen, wie viel Validierungsdaten benötigt werden
test_split = int(val_split+ (val_ratio * nsamples)) #bestimmen, wie viel Testdaten benötigt werden

#aufteilen der x-, und y-Daten
x_val,x_test,x_train = np.split(x_values, [val_split, test_split])
y_val,y_test,y_train = np.split(y_values, [val_split, test_split])

#Überprüfen ob das Aufteilen korrekt vollzogen wurde
assert(x_train.size + x_val.size + x_test.size) == nsamples
assert(y_train.size + y_val.size + y_test.size) == nsamples

"""Ploten der jeweiligen Datensätze:"""

plt.plot(x_train,y_train,'b.', label = "Training")
plt.plot(x_val,y_val,'r.', label = "Validation")
plt.plot(x_test,y_test,'g.', label = "Test")
plt.legend()
plt.show()

"""# Erstellen und trainieren des Modells"""

model = tf.keras.Sequential()
model.add(layers.Dense(16, activation='relu', input_shape=(1,)))
model.add(layers.Dense(16, activation='relu'))
model.add(layers.Dense(1))

"""Überblick über Modell ausgeben:"""

model.summary()

"""Gewünscheten optimizer, loss-Funktion und Metrics definieren und dann das Modell komplieren: (in unserem Fall mit optimizer: rmsprop, loss-Funktion: mean absolute error )"""

model.compile(optimizer = 'rmsprop', loss='mae', metrics=['mae'])

"""Trainieren des Modells"""

history=model.fit(
    x_train,
    y_train,
    epochs=500,
    batch_size=100,
    validation_data=(x_val,y_val)
)

"""Plotten des Trainingsvorganges"""

loss = history.history['loss']
val_loss = history.history['val_loss']

epochs = range(1, len(loss)+1)

plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validationloss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

"""# Testen des Modells"""

predictions = model.predict(x_test)

plt.clf()
plt.title("Vergleich zwischen Modellergebnis und tatsächlichem Wert")
plt.plot(x_test,y_test,'b.',label = 'tatsächlicher Wert')
plt.plot(x_test,predictions,'r.',label = 'Modellergebnis')
plt.legend()
plt.show()

"""#Konvertieren des Keras Modells zu tflite"""

converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]
tflite_model = converter.convert()
open(tflite_model_name +'.tflite','wb').write(tflite_model)

"""Erzeugen von C-Code aus der tflite-Datei"""

#Funktion, die Hex-Werte in ein Array konvertiert

def hex_to_c_array(hex_data, var_name):

  c_str = ''

  # Create header guard
  c_str += '#ifndef ' + var_name.upper() + '_H\n'
  c_str += '#define ' + var_name.upper() + '_H\n\n'

  # Add array length at top of file
  c_str += '\nunsigned int ' + var_name + '_len = ' + str(len(hex_data)) + ';\n'

  # Declare C variable
  c_str += 'unsigned char ' + var_name + '[] = {'
  hex_array = []
  for i, val in enumerate(hex_data) :

    # Construct string from hex
    hex_str = format(val, '#04x')

    # Add formatting so each line stays within 80 characters
    if (i + 1) < len(hex_data):
      hex_str += ','
    if (i + 1) % 12 == 0:
      hex_str += '\n '
    hex_array.append(hex_str)

  # Add closing brace
  c_str += '\n ' + format(' '.join(hex_array)) + '\n};\n\n'

  # Close out header guard
  c_str += '#endif //' + var_name.upper() + '_H'

  return c_str

"""Schreiben des Modells in eine C-Datei"""

with open(c_model_name + '.h','w') as file:
  file.write(hex_to_c_array(tflite_model, c_model_name))